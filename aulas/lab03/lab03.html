<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Lab.03 || CV - 2025.2</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="lab03.css">
    <link rel="stylesheet" href="../../menu.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"
        integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA=="
        crossorigin="anonymous" />
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Dancing+Script:wght@700&display=swap">
    <!-- Slick CSS no <head> -->
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.css" />
    <link rel="stylesheet" type="text/css"
        href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick-theme.css" />
    <script type="module" src="../image-slider-2x.js"></script>
</head>

<!-- JQuery + Slick JS -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.min.js"></script>

<!-- Arquivo JS externo -->
<script src="lab03.js"></script>

<body>

    <div class="container">
        <nav>
            <ul class="mcd-menu">
                <!-- <li>
                    <a href="">
                        <i class="fa fa-home"></i>
                        <div>
                            <strong>Home</strong>
                            <small>Incompleto</small>
                        </div>
                    </a>
                </li> -->
                <li>
                    <a href="../../index.html">
                        <i class="fa fa-edit"></i>
                        <div>
                            <strong>Sobre nós</strong>
                            <small>Completo</small>
                        </div>
                    </a>
                </li>
                <li>
                    <a href="../aulas.html" class="active">
                        <i class="fa fa-id-card"></i>
                        <div>
                            <strong>Aulas</strong>
                            <small>Incompleto</small>
                        </div>
                    </a>
                </li>
                <li>
                    <a href="../../trabalho/trabalho.html">
                        <i class="fa fa-archive"></i>
                        <div>
                            <strong>Projeto</strong>
                            <small>Incompleto</small>
                        </div>
                    </a>
                </li>
            </ul>
        </nav>
    </div>

    <div class="principal">

        <h1 class="titulo">Laboratório 3 – Câmera Estéreo</h1>
        <!-- <br>
        <div class = "about-btns">
            <button 
                onclick="document.location='lab2.html'" type = "button" 
                class = "btn btn-pink">Fotos e Vídeos</button>
        </div>
        <br> -->
        <div class="integrantes-list">
            <div class="integrante-card">
                <span class="integrante-nome">Lucas Sanchez Bitencourt</span>
                <span class="integrante-ra">RA 11201921617</span>
            </div>
            <div class="integrante-card">
                <span class="integrante-nome">Marcela Ceschim Caburlão</span>
                <span class="integrante-ra">RA 11201920483</span>
            </div>
            <div class="integrante-card">
                <span class="integrante-nome">Michael Franklin Saito</span>
                <span class="integrante-ra">RA 11201810988</span>
            </div>
            <div class="integrante-card">
                <span class="integrante-nome">Data de execução:</span>
                <span class="integrante-ra">02/07/2025</span>
            </div>
            <div class="integrante-card">
                <span class="integrante-nome">Data de publicação:</span>
                <span class="integrante-ra">02/07/2025</span>
            </div>
        </div>

        <!-- <p><mark>- Título do relatório</mark></p> -->
        <!-- <p><mark>- Nome completo dos autores do relatório</mark></p> -->
        <!-- <p><mark>- Data de realização dos experimentos</mark></p> -->
        <!-- <p><mark>- Data de publicação do relatório</mark></p>
        <p><mark>- Introdução – apresentando o que será descrito e relatado, bem como uma breve introdução ao
                assunto</mark></p>
        <p><mark>- Procedimentos experimentais – explicando como realizar e executar as atividades</mark></p>
        <p><mark>- Análise e discussão dos estudos realizados</mark></p>
        <p><mark>- Conclusões</mark></p>
        <p><mark>- Referências consultadas e indicadas</mark></p>
        <br> -->



        <h2>Introdução</h2>
        <br>
        <p>
            &emsp; A estereoscopia é uma técnica de visão computacional que busca reconstruir a percepção tridimensional
            a partir de imagens capturadas por duas câmeras posicionadas em paralelo, simulando a visão binocular
            humana. Essa técnica é fundamental para uma variedade de aplicações modernas, incluindo navegação de robôs
            autônomos, sistemas avançados de assistência ao motorista (ADAS), realidade aumentada e reconstrução 3D em
            modelagem digital.
        </p>
        <p>
            &emsp; No Laboratório 3 da disciplina de Visão Computacional, o objetivo foi compreender os conceitos
            fundamentais da geometria epipolar, realizar a montagem e calibração de uma câmera estéreo utilizando duas
            webcams e gerar imagens 3D em anáglifo. Este relatório detalha os procedimentos realizados, os resultados
            obtidos e uma análise crítica das etapas envolvidas.
        </p>


        <br>
        <h2>Procedimentos Experimentais</h2>
        <br>
        <p>
            &emsp; O experimento foi dividido em três etapas principais, conforme as orientações do laboratório:
        </p>
        <br>
        <h3>1. Estudo teórico</h3>
        <br>
        <p>
            &emsp; Antes de iniciar os experimentos, foi realizado um estudo sobre:
        </p>
        <p>
            &emsp; <b>Geometria Epipolar:</b> descreve a relação geométrica entre os pontos correspondentes em imagens
            capturadas por duas câmeras. A linha epipolar define onde o ponto correspondente deve estar na segunda
            imagem, reduzindo a busca de correspondências de 2D para 1D.
        </p>
        <p>
            &emsp; <b>Calibração de câmeras:</b> processo para determinar os parâmetros intrínsecos (foco, centro
            óptico, coeficientes de distorção) e extrínsecos (posição e orientação relativas entre as câmeras).
            As referências principais foram os tutoriais disponíveis no LearnOpenCV e os artigos indicados no PDF do
            laboratório.
        </p>
        <br>
        <h3>2. Montagem do sistema estéreo</h3>
        <br>
        <p>
            &emsp; Duas webcams idênticas foram posicionadas paralelamente com um espaçamento aproximado de 5 cm entre
            os eixos ópticos. As câmeras foram fixadas em uma superfície plana e rígida para evitar movimentos durante o
            processo de calibração.
        </p>
        <br>
        <h3>3. Execução prática com OpenCV</h3>
        <br>
        <p>
            &emsp; <b>Captura de imagens para calibração:</b> usando o script capture_images_you.py, capturamos 15
            imagens de
            um padrão de tabuleiro de xadrez em diferentes ângulos e posições.
        </p>
        <pre><code class="language-python">
import numpy as np 
import cv2
from tqdm import tqdm

# Set the path to the images captured by the left and right cameras
pathL = "./data_you/stereoL/"
pathR = "./data_you/stereoR/"

print("Extracting image coordinates of respective 3D pattern ....\n")

# Termination criteria for refining the detected corners
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)


objp = np.zeros((8*6,3), np.float32)
objp[:,:2] = np.mgrid[0:8,0:6].T.reshape(-1,2)

img_ptsL = []
img_ptsR = []
obj_pts = []

for i in tqdm(range(1,16)):
	imgL = cv2.imread(pathL+"img%d.png"%i)
	imgR = cv2.imread(pathR+"img%d.png"%i)
	imgL_gray = cv2.imread(pathL+"img%d.png"%i,0)
	imgR_gray = cv2.imread(pathR+"img%d.png"%i,0)

	outputL = imgL.copy()
	outputR = imgR.copy()

	retR, cornersR =  cv2.findChessboardCorners(outputR,(8,6),None)
	retL, cornersL = cv2.findChessboardCorners(outputL,(8,6),None)

	if retR and retL:
		obj_pts.append(objp)
		cv2.cornerSubPix(imgR_gray,cornersR,(11,11),(-1,-1),criteria)
		cv2.cornerSubPix(imgL_gray,cornersL,(11,11),(-1,-1),criteria)
		cv2.drawChessboardCorners(outputR,(8,6),cornersR,retR)
		cv2.drawChessboardCorners(outputL,(8,6),cornersL,retL)
		cv2.imshow('cornersR',outputR)
		cv2.imshow('cornersL',outputL)
		cv2.waitKey(0)

		img_ptsL.append(cornersL)
		img_ptsR.append(cornersR)


print("Calculating left camera parameters ... ")
# Calibrating left camera
retL, mtxL, distL, rvecsL, tvecsL = cv2.calibrateCamera(obj_pts,img_ptsL,imgL_gray.shape[::-1],None,None)
hL,wL= imgL_gray.shape[:2]
new_mtxL, roiL= cv2.getOptimalNewCameraMatrix(mtxL,distL,(wL,hL),1,(wL,hL))

print("Calculating right camera parameters ... ")
# Calibrating right camera
retR, mtxR, distR, rvecsR, tvecsR = cv2.calibrateCamera(obj_pts,img_ptsR,imgR_gray.shape[::-1],None,None)
hR,wR= imgR_gray.shape[:2]
new_mtxR, roiR= cv2.getOptimalNewCameraMatrix(mtxR,distR,(wR,hR),1,(wR,hR))


print("Stereo calibration .....")
flags = 0
flags |= cv2.CALIB_FIX_INTRINSIC
# Here we fix the intrinsic camara matrixes so that only Rot, Trns, Emat and Fmat are calculated.
# Hence intrinsic parameters are the same 

criteria_stereo= (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)


# This step is performed to transformation between the two cameras and calculate Essential and Fundamenatl matrix
retS, new_mtxL, distL, new_mtxR, distR, Rot, Trns, Emat, Fmat = cv2.stereoCalibrate(obj_pts,
                                                          img_ptsL,
                                                          img_ptsR,
                                                          new_mtxL,
                                                          distL,
                                                          new_mtxR,
                                                          distR,
                                                          imgL_gray.shape[::-1],
                                                          criteria_stereo,
                                                          flags)

# Once we know the transformation between the two cameras we can perform stereo rectification
# StereoRectify function
rectify_scale= 1 # if 0 image croped, if 1 image not croped
rect_l, rect_r, proj_mat_l, proj_mat_r, Q, roiL, roiR= cv2.stereoRectify(new_mtxL, distL, new_mtxR, distR,
                                                 imgL_gray.shape[::-1], Rot, Trns,
                                                 rectify_scale,(0,0))

# Use the rotation matrixes for stereo rectification and camera intrinsics for undistorting the image
# Compute the rectification map (mapping between the original image pixels and 
# their transformed values after applying rectification and undistortion) for left and right camera frames
Left_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxL, distL, rect_l, proj_mat_l,
                                             imgL_gray.shape[::-1], cv2.CV_16SC2)
Right_Stereo_Map= cv2.initUndistortRectifyMap(new_mtxR, distR, rect_r, proj_mat_r,
                                              imgR_gray.shape[::-1], cv2.CV_16SC2)


print("Saving paraeters ......")
cv_file = cv2.FileStorage("data_you/params_py.xml", cv2.FILE_STORAGE_WRITE)
cv_file.write("Left_Stereo_Map_x",Left_Stereo_Map[0])
cv_file.write("Left_Stereo_Map_y",Left_Stereo_Map[1])
cv_file.write("Right_Stereo_Map_x",Right_Stereo_Map[0])
cv_file.write("Right_Stereo_Map_y",Right_Stereo_Map[1])
cv_file.release()
        </code></pre>
        <p>
            &emsp; <b>Calibração da câmera estéreo:</b> o script calibrate_images_you.py foi executado para extrair as
            matrizes
            de calibração (M1, M2), os vetores de distorção (D1, D2), a matriz de rotação (R), o vetor de translação (T)
            e as matrizes de retificação (R1, R2).
        </p>
        <pre><code class="language-python">
import numpy as np
import cv2
import time

print("Checking the right and left camera IDs:")
print("Press (y) if IDs are correct and (n) to swap the IDs")
print("Press enter to start the process >> ")
input()

# Check for left and right camera IDs
CamL_id = 0
CamR_id = 2

CamL= cv2.VideoCapture(CamL_id)
CamR= cv2.VideoCapture(CamR_id)

for i in range(100):
    retL, frameL= CamL.read()
    retR, frameR= CamR.read()

cv2.imshow('imgL',frameL)
cv2.imshow('imgR',frameR)

if cv2.waitKey(0) & 0xFF == ord('y') or cv2.waitKey(0) & 0xFF == ord('Y'):
    CamL_id = 0
    CamR_id = 2
    print("Camera IDs maintained")

elif cv2.waitKey(0) & 0xFF == ord('n') or cv2.waitKey(0) & 0xFF == ord('N'):
    CamL_id = 2
    CamR_id = 0
    print("Camera IDs swapped")
else:
    print("Wrong input response")
    exit(-1)
CamR.release()
CamL.release()

CamL= cv2.VideoCapture(CamL_id)
CamR= cv2.VideoCapture(CamR_id)
output_path = "./data_you/"

start = time.time()
T = 10
count = 0

while True:
    timer = T - int(time.time() - start)
    retR, frameR= CamR.read()
    retL, frameL= CamL.read()
    
    img1_temp = frameL.copy()
    cv2.putText(img1_temp,"%r"%timer,(50,50),1,5,(55,0,0),5)
    cv2.imshow('imgR',frameR)
    cv2.imshow('imgL',img1_temp)

    grayR= cv2.cvtColor(frameR,cv2.COLOR_BGR2GRAY)
    grayL= cv2.cvtColor(frameL,cv2.COLOR_BGR2GRAY)

    # Find the chess board corners
    retR, cornersR = cv2.findChessboardCorners(grayR,(8,6),None)
    retL, cornersL = cv2.findChessboardCorners(grayL,(8,6),None)

    # If corners are detected in left and right image then we save it.
    #if (retR == True) and (retL == True) and timer <=0:
    if timer <=0:
        count+=1
        cv2.imwrite(output_path+'stereoR/img%d.png'%count,frameR)
        cv2.imwrite(output_path+'stereoL/img%d.png'%count,frameL)
    
    if timer <=0:
        start = time.time()
    
    # Press esc to exit
    if cv2.waitKey(1) & 0xFF == 27:
        print("Closing the cameras!")
        break

# Release the Cameras
CamR.release()
CamL.release()
cv2.destroyAllWindows()
        </code></pre>
        <p>
            &emsp; <b>Captura de vídeos:</b> utilizando o script capture_video_you.py, capturamos vídeos sincronizados
            nas duas câmeras para posteriormente criar os vídeos em 3D.
        </p>
        <pre><code class="language-python">
import numpy as np
import cv2 as cv
import os

# Certifique-se de que o diretório existe
output_dir = os.path.expanduser('~/data_you/')
os.makedirs(output_dir, exist_ok=True)

# Inicializa as câmeras
capL = cv.VideoCapture(0)
capR = cv.VideoCapture(2)

# Verifica se ambas as câmeras foram abertas com sucesso
if not capL.isOpened():
    print("Não foi possível abrir a câmera esquerda (capL)")
    exit()

if not capR.isOpened():
    print("Não foi possível abrir a câmera direita (capR)")
    exit()

# Obtém as propriedades das câmeras (usa a da esquerda como base)
width = int(capL.get(cv.CAP_PROP_FRAME_WIDTH))
height = int(capL.get(cv.CAP_PROP_FRAME_HEIGHT))
fps = 20.0

while True:
    # Captura os frames de ambas as câmeras
    retL, frameL = capL.read()
    retR, frameR = capR.read()

    if not retL or not retR:
        print("Erro ao capturar frames. Encerrando...")
        break


    # Exibe os vídeos em janelas separadas
    cv.imshow('frameL', frameL)
    cv.imshow('frameR', frameR)

    # Sai com 'q'
    if cv.waitKey(1) == ord('q'):
        break

# Libera tudo
#capL.release()
#capR.release()
#cv.destroyAllWindows()

fourcc = cv.VideoWriter_fourcc(*'XVID')
outL = cv.VideoWriter('stereoL.avi', fourcc, fps, (width, height))
outR = cv.VideoWriter('stereoR.avi', fourcc, fps, (width, height))

while capL.isOpened():
    retL, frameL = capL.read()
    retR, frameR = capR.read()
    if not retL:
        print("Can't receive frame (stream end?). Exiting ...")
        break
    # write the flipped frame
    outL.write(frameL)
    outR.write(frameR)
    cv.imshow('frameL', frameL)
    cv.imshow('frameR', frameR)
    if cv.waitKey(1) == ord('q'):
        break

# Release everything if job is finished
capL.release()
capR.release()
outL.release()
outR.release()
cv.destroyAllWindows()
        </code></pre>
        <p>
            &emsp; <b>Geração e gravação de vídeos 3D:</b> utilizando o script movie3d_you.py, visualizamos a cena com
            efeito 3D
            em tempo real com óculos anáglifos. Também modificamos o código para salvar os vídeos resultantes.
        </p>
        <pre><code class="language-python">
import numpy as np 
import cv2


CamL_id = "data_you/stereoL.mp4"
CamR_id = "data_you/stereoR.mp4"

CamL= cv2.VideoCapture(CamL_id)
CamR= cv2.VideoCapture(CamR_id)

print("Reading parameters ......")
cv_file = cv2.FileStorage("data_you/params_py.xml", cv2.FILE_STORAGE_READ)

Left_Stereo_Map_x = cv_file.getNode("Left_Stereo_Map_x").mat()
Left_Stereo_Map_y = cv_file.getNode("Left_Stereo_Map_y").mat()
Right_Stereo_Map_x = cv_file.getNode("Right_Stereo_Map_x").mat()
Right_Stereo_Map_y = cv_file.getNode("Right_Stereo_Map_y").mat()
cv_file.release()

print("Starting while ......")

fourcc = cv2.VideoWriter_fourcc(*'XVID')
fps = 20.0
out = cv2.VideoWriter('movie3d_1.avi', fourcc, fps, (700, 700))


while True:
	retR, imgR= CamR.read()
	retL, imgL= CamL.read()
	
	if retL and retR:
		imgR_gray = cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)
		imgL_gray = cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY)

		Left_nice= cv2.remap(imgL,Left_Stereo_Map_x,Left_Stereo_Map_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)
		Right_nice= cv2.remap(imgR,Right_Stereo_Map_x,Right_Stereo_Map_y, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)

		output = Right_nice.copy()
		output[:,:,0] = Right_nice[:,:,0]
		output[:,:,1] = Right_nice[:,:,1]
		output[:,:,2] = Left_nice[:,:,2]

		# output = Left_nice+Right_nice
		output = cv2.resize(output,(700,700))
		cv2.namedWindow("3D movie",cv2.WINDOW_NORMAL)
		cv2.resizeWindow("3D movie",700,700)
		out.write(output)
		cv2.imshow("3D movie",output)

		cv2.waitKey(1)
	
	else:
		break

out.release()
cv2.destroyAllWindows()
        </code></pre>
        <br>

        <!-- Slider de imagens estéreo -->
        <div style="margin: 16px 0;">
            <h3>3. Resultados</h3>
        <br>
            <h4>Pares de imagens estéreo de exemplo</h4>
            <br>
            <image-slider-2x images='[
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img1.png&quot;,&quot;alt&quot;:&quot;Esquerda 1&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img1.png&quot;,&quot;alt&quot;:&quot;Direita 1&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img2.png&quot;,&quot;alt&quot;:&quot;Esquerda 2&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img2.png&quot;,&quot;alt&quot;:&quot;Direita 2&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img3.png&quot;,&quot;alt&quot;:&quot;Esquerda 3&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img3.png&quot;,&quot;alt&quot;:&quot;Direita 3&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img4.png&quot;,&quot;alt&quot;:&quot;Esquerda 4&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img4.png&quot;,&quot;alt&quot;:&quot;Direita 4&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img5.png&quot;,&quot;alt&quot;:&quot;Esquerda 5&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img5.png&quot;,&quot;alt&quot;:&quot;Direita 5&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img6.png&quot;,&quot;alt&quot;:&quot;Esquerda 6&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img6.png&quot;,&quot;alt&quot;:&quot;Direita 6&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img7.png&quot;,&quot;alt&quot;:&quot;Esquerda 7&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img7.png&quot;,&quot;alt&quot;:&quot;Direita 7&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img8.png&quot;,&quot;alt&quot;:&quot;Esquerda 8&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img8.png&quot;,&quot;alt&quot;:&quot;Direita 8&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img9.png&quot;,&quot;alt&quot;:&quot;Esquerda 9&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img9.png&quot;,&quot;alt&quot;:&quot;Direita 9&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img10.png&quot;,&quot;alt&quot;:&quot;Esquerda 10&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img10.png&quot;,&quot;alt&quot;:&quot;Direita 10&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img11.png&quot;,&quot;alt&quot;:&quot;Esquerda 11&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img11.png&quot;,&quot;alt&quot;:&quot;Direita 11&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img12.png&quot;,&quot;alt&quot;:&quot;Esquerda 12&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img12.png&quot;,&quot;alt&quot;:&quot;Direita 12&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img13.png&quot;,&quot;alt&quot;:&quot;Esquerda 13&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img13.png&quot;,&quot;alt&quot;:&quot;Direita 13&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img14.png&quot;,&quot;alt&quot;:&quot;Esquerda 14&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img14.png&quot;,&quot;alt&quot;:&quot;Direita 14&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoL/img15.png&quot;,&quot;alt&quot;:&quot;Esquerda 15&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data/stereoR/img15.png&quot;,&quot;alt&quot;:&quot;Direita 15&quot;}
            ]'></image-slider-2x>
        </div>
        <div style="margin: 16px 0;">
            <h4>Pares de imagens estéreo capturadas</h4>
            <br>
            <image-slider-2x images='[
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img1.png&quot;,&quot;alt&quot;:&quot;Esquerda 1&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img1.png&quot;,&quot;alt&quot;:&quot;Direita 1&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img2.png&quot;,&quot;alt&quot;:&quot;Esquerda 2&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img2.png&quot;,&quot;alt&quot;:&quot;Direita 2&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img3.png&quot;,&quot;alt&quot;:&quot;Esquerda 3&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img3.png&quot;,&quot;alt&quot;:&quot;Direita 3&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img4.png&quot;,&quot;alt&quot;:&quot;Esquerda 4&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img4.png&quot;,&quot;alt&quot;:&quot;Direita 4&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img5.png&quot;,&quot;alt&quot;:&quot;Esquerda 5&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img5.png&quot;,&quot;alt&quot;:&quot;Direita 5&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img6.png&quot;,&quot;alt&quot;:&quot;Esquerda 6&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img6.png&quot;,&quot;alt&quot;:&quot;Direita 6&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img7.png&quot;,&quot;alt&quot;:&quot;Esquerda 7&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img7.png&quot;,&quot;alt&quot;:&quot;Direita 7&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img8.png&quot;,&quot;alt&quot;:&quot;Esquerda 8&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img8.png&quot;,&quot;alt&quot;:&quot;Direita 8&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img9.png&quot;,&quot;alt&quot;:&quot;Esquerda 9&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img9.png&quot;,&quot;alt&quot;:&quot;Direita 9&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img10.png&quot;,&quot;alt&quot;:&quot;Esquerda 10&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img10.png&quot;,&quot;alt&quot;:&quot;Direita 10&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img11.png&quot;,&quot;alt&quot;:&quot;Esquerda 11&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img11.png&quot;,&quot;alt&quot;:&quot;Direita 11&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img12.png&quot;,&quot;alt&quot;:&quot;Esquerda 12&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img12.png&quot;,&quot;alt&quot;:&quot;Direita 12&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img13.png&quot;,&quot;alt&quot;:&quot;Esquerda 13&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img13.png&quot;,&quot;alt&quot;:&quot;Direita 13&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img14.png&quot;,&quot;alt&quot;:&quot;Esquerda 14&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img14.png&quot;,&quot;alt&quot;:&quot;Direita 14&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoL/img15.png&quot;,&quot;alt&quot;:&quot;Esquerda 15&quot;},
                {&quot;src&quot;:&quot;Lab3_stereo-camera/data_you/stereoR/img15.png&quot;,&quot;alt&quot;:&quot;Direita 15&quot;}
            ]'></image-slider-2x>
        </div>
        <br>

        <!-- Stereo synchronized video players -->
        <div style="margin: 16px 0;">
            <h4>Pares de vídeos estéreo sincronizados</h4>
            <br>
            <div style="display: flex; gap: 16px; justify-content: center; align-items: flex-start;">
                <div style="text-align:center;">
                    <video id="stereoL_ex" width="400" controls>
                        <source src="Lab3_stereo-camera/data_you/stereoL2.mp4" type="video/mp4">
                        Seu navegador não suporta o elemento de vídeo.
                    </video>
                </div>
                <div style="text-align:center;">
                    <video id="stereoR_ex" width="400" controls>
                        <source src="Lab3_stereo-camera/data_you/stereoR2.mp4" type="video/mp4">
                        Seu navegador não suporta o elemento de vídeo.
                    </video>
                </div>
            </div>
            <br>
            <div style="display: flex; gap: 16px; justify-content: center; align-items: flex-start;">
                <div style="text-align:center;">
                    <video id="stereoL" width="400" controls>
                        <source src="Lab3_stereo-camera/data_you/stereoL.mp4" type="video/mp4">
                        Seu navegador não suporta o elemento de vídeo.
                    </video>
                </div>
                <div style="text-align:center;">
                    <video id="stereoR" width="400" controls>
                        <source src="Lab3_stereo-camera/data_you/stereoR.mp4" type="video/mp4">
                        Seu navegador não suporta o elemento de vídeo.
                    </video>
                </div>
            </div>
        </div>

        <!-- Stereo synchronized video players -->
        <div style="margin: 16px 0;">
            <h4>Vídeos 3D resultantes</h4>
            <br>
            <div style="display: flex; gap: 16px; justify-content: center; align-items: flex-start;">
                <div style="text-align:center;">
                    <video id="stereoL_ex" width="400" controls>
                        <source src="Lab3_stereo-camera/data_you/movie3d_1.mp4" type="video/mp4">
                        Seu navegador não suporta o elemento de vídeo.
                    </video>
                </div>
                <div style="text-align:center;">
                    <video id="stereoR_ex" width="400" controls>
                        <source src="Lab3_stereo-camera/data_you/movie3d_2.mp4" type="video/mp4">
                        Seu navegador não suporta o elemento de vídeo.
                    </video>
                </div>
            </div>
            <br>
        </div>

        <!-- %%%%%%%%%%%%%%%%%%%%%%%%%%%% Análise e discussão dos estudos realizados %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%-->

        <h2>Análise e discussão dos estudos realizados</h2>
        <br>
        <p>
            &emsp; A calibração resultou em parâmetros que permitiram a correção das distorções ópticas das lentes das
            webcams. A retificação das imagens foi eficaz, alinhando as linhas epipolares e facilitando a geração do
            mapa de disparidade.
        </p>
        <p>
            &emsp; Observações e desafios:
        </p>
        <ul>
            <li>A fixação das câmeras é crítica; pequenos desalinhamentos podem gerar erros na profundidade.</li>
            <li>O efeito 3D ao vivo apresentou boa percepção de profundidade, especialmente em objetos localizados a
                menos de 1 metro.
            </li>
            <li>A gravação em vídeo apresentou uma ligeira perda de qualidade no efeito anáglifo devido à compressão
                mp4.
            </li>
            <li>As diferenças entre os resultados ao vivo e o vídeo gravado foram discutidas pela equipe, e alguns
                integrantes relataram maior conforto visual com a cena ao vivo.
            </li>
        </ul>

        <br>
        <h2>Conclusões</h2>
        <br>
        <p>
            &emsp; A atividade permitiu consolidar conceitos teóricos e práticos sobre visão estéreo e geometria
            epipolar. Demonstramos a viabilidade de construir um sistema estéreo com recursos acessíveis, utilizando
            webcams comuns e a biblioteca OpenCV. O experimento destacou a importância da calibração e da retificação
            para obtenção de um efeito 3D satisfatório.
        </p>
        <p>
            &emsp; Aplicações potenciais do aprendizado incluem sistemas de navegação autônoma, reconstrução 3D para
            engenharia reversa e aplicações em realidade aumentada. Como limitação, ressalta-se a sensibilidade do
            sistema a desalinhamentos físicos e variações de iluminação.
        </p>



        <br>
        <h2>Referências</h2>
        <br>
        <p>
        <ul>
            <li>
                <p>[1] Making A Low-Cost Stereo Camera Using OpenCV:</p>
                <p><a href="https://learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/"
                        target="_blank">https://learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/</a></p>
                <p>Código: <a href="https://github.com/spmallick/learnopencv/tree/master/stereo-camera"
                        target="_blank">https://github.com/spmallick/learnopencv/tree/master/stereo-camera</a></p>
            </li>
            <br>

            <li>
                <p>[2] Introduction to Epipolar Geometry and Stereo Vision:</p>
                <p><a href="https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/"
                        target="_blank">https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/</a>
                </p>
                <p>Código: <a
                        href="https://github.com/spmallick/learnopencv/tree/master/EpipolarGeometryAndStereoVision"
                        target="_blank">https://github.com/spmallick/learnopencv/tree/master/EpipolarGeometryAndStereoVision</a>
                </p>
            </li>
            <br>

            <li>
                <p>[3] Understanding Lens Distortion:</p>
                <p><a href="https://learnopencv.com/understanding-lens-distortion/"
                        target="_blank">https://learnopencv.com/understanding-lens-distortion/</a></p>
                <p>Código: <a href="https://github.com/spmallick/learnopencv/tree/master/UnderstandingLensDistortion"
                        target="_blank">https://github.com/spmallick/learnopencv/tree/master/UnderstandingLensDistortion</a>
                </p>
            </li>
            <br>

            <li>
                <p>[4] C. Loop and Z. Zhang. Computing Rectifying Homographies for Stereo Vision.</p>
                <p>IEEE Conf. Computer Vision and Pattern Recognition, 1999.</p>
            </li>
            <br>

            <li>
                <p>[5] Geometry of Image Formation:</p>
                <p><a href="https://learnopencv.com/geometry-of-image-formation/"
                        target="_blank">https://learnopencv.com/geometry-of-image-formation/</a></p>
            </li>

        </ul>
        </p>
    </div>

</body>
<script>
    // Stereo example videos sync (no DOMContentLoaded needed since script is at end of body)
    const vL_ex = document.getElementById('stereoL_ex');
    const vR_ex = document.getElementById('stereoR_ex');
    let seeking_ex = false;
    function syncPlayPauseEx(src, dest) {
        src.addEventListener('play', () => { if (dest.paused) dest.play(); });
        src.addEventListener('pause', () => { if (!dest.paused) dest.pause(); });
    }
    function syncSeekEx(src, dest) {
        src.addEventListener('seeking', () => {
            if (!seeking_ex) {
                seeking_ex = true;
                dest.currentTime = src.currentTime;
            }
        });
        src.addEventListener('seeked', () => { seeking_ex = false; });
    }
    if (vL_ex && vR_ex) {
        syncPlayPauseEx(vL_ex, vR_ex);
        syncPlayPauseEx(vR_ex, vL_ex);
        syncSeekEx(vL_ex, vR_ex);
        syncSeekEx(vR_ex, vL_ex);
    }

    // Stereo user videos sync
    const vL = document.getElementById('stereoL');
    const vR = document.getElementById('stereoR');
    let seeking = false;
    function syncPlayPause(src, dest) {
        src.addEventListener('play', () => { if (dest.paused) dest.play(); });
        src.addEventListener('pause', () => { if (!dest.paused) dest.pause(); });
    }
    function syncSeek(src, dest) {
        src.addEventListener('seeking', () => {
            if (!seeking) {
                seeking = true;
                dest.currentTime = src.currentTime;
            }
        });
        src.addEventListener('seeked', () => { seeking = false; });
    }
    if (vL && vR) {
        syncPlayPause(vL, vR);
        syncPlayPause(vR, vL);
        syncSeek(vL, vR);
        syncSeek(vR, vL);
    }
</script>

</html>