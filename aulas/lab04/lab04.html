<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lab.04 || CV - 2025.2</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="lab04.css" />
  <link rel="stylesheet" href="../../menu.css" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA=="
    crossorigin="anonymous" />
  <link rel="preconnect" href="https://fonts.gstatic.com" />
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Dancing+Script:wght@700&display=swap" />
  <!-- Slick CSS no <head> -->
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.css" />
  <link rel="stylesheet" type="text/css"
    href="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick-theme.css" />
  <script type="module" src="../image-slider-2x.js"></script>
</head>

<!-- JQuery + Slick JS -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/slick-carousel@1.8.1/slick/slick.min.js"></script>

<script src="lab04.js"></script>

<!-- Arquivo JS externo -->
<!-- <script src="lab03.js"></script> -->

<body>
  <div class="container">
    <nav>
      <ul class="mcd-menu">
        <!-- <li>
                    <a href="">
                        <i class="fa fa-home"></i>
                        <div>
                            <strong>Home</strong>
                            <small>Incompleto</small>
                        </div>
                    </a>
                </li> -->
        <li>
          <a href="../../index.html">
            <i class="fa fa-edit"></i>
            <div>
              <strong>Sobre nós</strong>
              <small>Completo</small>
            </div>
          </a>
        </li>
        <li>
          <a href="../aulas.html" class="active">
            <i class="fa fa-id-card"></i>
            <div>
              <strong>Aulas</strong>
              <small>Incompleto</small>
            </div>
          </a>
        </li>
        <li>
          <a href="../../trabalho/trabalho.html">
            <i class="fa fa-archive"></i>
            <div>
              <strong>Projeto</strong>
              <small>Incompleto</small>
            </div>
          </a>
        </li>
      </ul>
    </nav>
  </div>

  <div class="principal">
    <h1 class="titulo">Laboratório 4 – Mapa de Profundidade</h1>
    <!-- <br>
        <div class = "about-btns">
            <button 
                onclick="document.location='lab2.html'" type = "button" 
                class = "btn btn-pink">Fotos e Vídeos</button>
        </div>
        <br> -->
    <div class="integrantes-list">
      <div class="integrante-card">
        <span class="integrante-nome">Lucas Sanchez Bitencourt</span>
        <span class="integrante-ra">RA 11201921617</span>
      </div>
      <div class="integrante-card">
        <span class="integrante-nome">Marcela Ceschim Caburlão</span>
        <span class="integrante-ra">RA 11201920483</span>
      </div>
      <div class="integrante-card">
        <span class="integrante-nome">Michael Franklin Saito</span>
        <span class="integrante-ra">RA 11201810988</span>
      </div>
      <div class="integrante-card">
        <span class="integrante-nome">Data de execução:</span>
        <span class="integrante-ra">21/07/2025</span>
      </div>
      <div class="integrante-card">
        <span class="integrante-nome">Data de publicação:</span>
        <span class="integrante-ra">XX/07/2025</span>
      </div>
    </div>

    <!-- <p><mark>- Título do relatório</mark></p> -->
    <!-- <p><mark>- Nome completo dos autores do relatório</mark></p> -->
    <!-- <p><mark>- Data de realização dos experimentos</mark></p> -->
    <!-- <p><mark>- Data de publicação do relatório</mark></p>
        <p><mark>- Introdução – apresentando o que será descrito e relatado, bem como uma breve introdução ao
                assunto</mark></p>
        <p><mark>- Procedimentos experimentais – explicando como realizar e executar as atividades</mark></p>
        <p><mark>- Análise e discussão dos estudos realizados</mark></p>
        <p><mark>- Conclusões</mark></p>
        <p><mark>- Referências consultadas e indicadas</mark></p>
        <br> -->

    <h2>Introdução</h2>
    <br />
    <p>
      &emsp; A visão estereoscópica é uma técnica de reconstrução 3D que
      utiliza duas ou mais imagens capturadas a partir de pontos de vista
      diferentes para estimar a profundidade de uma cena. Ela se baseia no
      princípio da geometria epipolar, que estabelece a relação entre pontos
      correspondentes nas imagens das duas câmeras.
    </p>
    <p>
      &emsp; Um dos resultados principais desse processo é o mapa de
      disparidade, que representa o deslocamento (em pixels) entre pontos
      correspondentes das imagens esquerda e direita. A partir desse mapa, é
      possível calcular o mapa de profundidade, estimando distâncias relativas
      entre os objetos da cena e as câmeras.
    </p>
    <p>
      &emsp; Técnicas como o algoritmo Block Matching e o StereoSGBM
      (Semi-Global Block Matching) são amplamente utilizadas em aplicações que
      vão desde veículos autônomos até sistemas de realidade aumentada.
    </p>
    <br />
    <p>
      &emsp; Referências principais para estudo teórico:
    </p>
    <br />
    <ul>
      <li>
        Geometria Epipolar:
        <a href="https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/" target="_blank">
          https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/
        </a>
      </li>
      <li>
        Mapa de Profundidade:
        <a href="https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html" target="_blank">
          https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html
        </a>
      </li>
      <li>
        Percepção de Profundidade com Câmeras Estéreo:
        <a href="https://learnopencv.com/depth-perception-using-stereo-camera-python-c/" target="_blank">
          https://learnopencv.com/depth-perception-using-stereo-camera-python-c/
        </a>
      </li>
    </ul>

    <br />
    <h2>Procedimentos Experimentais</h2>
    <br />
    <h3>Calibração Estéreo</h3>
    <br />
    <p>&emsp; O processo iniciou com a calibração estéreo da câmera, utilizando o padrão de tabuleiro de xadrez para
      estimar os parâmetros intrínsecos e extrínsecos. As imagens foram capturadas com o script capture_images.py e
      processadas pelo calibrate_you.py, gerando o arquivo params_py.xml, que armazena as matrizes de
      calibração e distorção. Esses códigos podem ser consultados na página do <a href="../lab03/lab03.html"
        target="_blank">Laboratório 3</a>.</p>

    <br />
    <h3>Cálculo do Mapa de Disparidade</h3>
    <br />
    <p>&emsp; A geração do mapa de disparidade é uma das etapas mais importantes do processo de percepção de
      profundidade por meio de visão estéreo. Esse mapa representa, pixel a pixel, a diferença de posição de um mesmo
      ponto da cena entre as duas imagens capturadas pelas câmeras estéreo (esquerda e direita). Essa diferença, chamada
      de disparidade, está diretamente relacionada à distância do objeto até a câmera: quanto maior a disparidade, mais
      próximo o objeto está.</p>
    <br />
    <p>&emsp; Para realizar essa etapa, foi utilizado o algoritmo Block Matching (BM) do OpenCV, um dos métodos
      clássicos para correspondência estéreo. O algoritmo funciona comparando blocos de pixels entre as duas imagens,
      tentando encontrar, para cada pixel da imagem da esquerda, a melhor correspondência na imagem da direita, dentro
      de uma janela de busca. A posição com a melhor correspondência determina o valor da disparidade para aquele ponto.
    </p>
    <p>&emsp; O programa base utilizado para essa tarefa foi o disparity_params_gui.py, fornecido pelo repositório
      oficial do projeto. Esse script já possuía uma interface gráfica interativa, permitindo o ajuste dinâmico dos
      principais parâmetros do algoritmo BM. No entanto, foi necessário adaptá-lo para carregar corretamente os
      parâmetros de calibração estéreo gerados previamente e salvos no arquivo params_py.xml. Esse arquivo contém as
      informações intrínsecas e extrínsecas das câmeras, como matrizes de calibração, coeficientes de distorção e
      matrizes de retificação, que são essenciais para o alinhamento correto das imagens antes do cálculo de
      disparidade.
    </p>
    <pre><code class="language-python">
import numpy as np 
import cv2


# Check for left and right camera IDs
# These values can change depending on the system
CamL_id = 2 # Camera ID for left camera
CamR_id = 0 # Camera ID for right camera

CamL= cv2.VideoCapture(CamL_id)
CamR= cv2.VideoCapture(CamR_id)

# Reading the mapping values for stereo image rectification
cv_file = cv2.FileStorage("params_py.xml", cv2.FILE_STORAGE_READ)
Left_Stereo_Map_x = cv_file.getNode("Left_Stereo_Map_x").mat()
Left_Stereo_Map_y = cv_file.getNode("Left_Stereo_Map_y").mat()
Right_Stereo_Map_x = cv_file.getNode("Right_Stereo_Map_x").mat()
Right_Stereo_Map_y = cv_file.getNode("Right_Stereo_Map_y").mat()
cv_file.release()

def nothing(x):
    pass

cv2.namedWindow('disp',cv2.WINDOW_NORMAL)
cv2.resizeWindow('disp',600,600)

cv2.createTrackbar('numDisparities','disp',1,17,nothing)
cv2.createTrackbar('blockSize','disp',5,50,nothing)
cv2.createTrackbar('preFilterType','disp',1,1,nothing)
cv2.createTrackbar('preFilterSize','disp',2,25,nothing)
cv2.createTrackbar('preFilterCap','disp',5,62,nothing)
cv2.createTrackbar('textureThreshold','disp',10,100,nothing)
cv2.createTrackbar('uniquenessRatio','disp',15,100,nothing)
cv2.createTrackbar('speckleRange','disp',0,100,nothing)
cv2.createTrackbar('speckleWindowSize','disp',3,25,nothing)
cv2.createTrackbar('disp12MaxDiff','disp',5,25,nothing)
cv2.createTrackbar('minDisparity','disp',5,25,nothing)

# Creating an object of StereoBM algorithm
stereo = cv2.StereoBM_create()

while True:

	# Capturing and storing left and right camera images
	retL, imgL= CamL.read()
	retR, imgR= CamR.read()
	
	# Proceed only if the frames have been captured
	if retL and retR:
		imgR_gray = cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)
		imgL_gray = cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY)

		# Applying stereo image rectification on the left image
		Left_nice= cv2.remap(imgL_gray,
							Left_Stereo_Map_x,
							Left_Stereo_Map_y,
							cv2.INTER_LANCZOS4,
							cv2.BORDER_CONSTANT,
							0)
		
		# Applying stereo image rectification on the right image
		Right_nice= cv2.remap(imgR_gray,
							Right_Stereo_Map_x,
							Right_Stereo_Map_y,
							cv2.INTER_LANCZOS4,
							cv2.BORDER_CONSTANT,
							0)

		# Updating the parameters based on the trackbar positions
		numDisparities = cv2.getTrackbarPos('numDisparities','disp')*16
		blockSize = cv2.getTrackbarPos('blockSize','disp')*2 + 5
		preFilterType = cv2.getTrackbarPos('preFilterType','disp')
		preFilterSize = cv2.getTrackbarPos('preFilterSize','disp')*2 + 5
		preFilterCap = cv2.getTrackbarPos('preFilterCap','disp')
		textureThreshold = cv2.getTrackbarPos('textureThreshold','disp')
		uniquenessRatio = cv2.getTrackbarPos('uniquenessRatio','disp')
		speckleRange = cv2.getTrackbarPos('speckleRange','disp')
		speckleWindowSize = cv2.getTrackbarPos('speckleWindowSize','disp')*2
		disp12MaxDiff = cv2.getTrackbarPos('disp12MaxDiff','disp')
		minDisparity = cv2.getTrackbarPos('minDisparity','disp')
		
		# Setting the updated parameters before computing disparity map
		stereo.setNumDisparities(numDisparities)
		stereo.setBlockSize(blockSize)
		stereo.setPreFilterType(preFilterType)
		stereo.setPreFilterSize(preFilterSize)
		stereo.setPreFilterCap(preFilterCap)
		stereo.setTextureThreshold(textureThreshold)
		stereo.setUniquenessRatio(uniquenessRatio)
		stereo.setSpeckleRange(speckleRange)
		stereo.setSpeckleWindowSize(speckleWindowSize)
		stereo.setDisp12MaxDiff(disp12MaxDiff)
		stereo.setMinDisparity(minDisparity)

		# Calculating disparity using the StereoBM algorithm
		disparity = stereo.compute(Left_nice,Right_nice)
		# NOTE: compute returns a 16bit signed single channel image,
		# CV_16S containing a disparity map scaled by 16. Hence it 
		# is essential to convert it to CV_32F and scale it down 16 times.

		# Converting to float32 
		disparity = disparity.astype(np.float32)

		# Scaling down the disparity values and normalizing them 
		disparity = (disparity/16.0 - minDisparity)/numDisparities

		# Displaying the disparity map
		cv2.imshow("disp",disparity)

		# Close window using esc key
		if cv2.waitKey(1) == 27:
			break
	
	else:
		CamL= cv2.VideoCapture(CamL_id)
		CamR= cv2.VideoCapture(CamR_id)

print("Saving depth estimation paraeters ......")

cv_file = cv2.FileStorage("depth_estmation_params_py.xml", cv2.FILE_STORAGE_WRITE)
cv_file.write("numDisparities",numDisparities)
cv_file.write("blockSize",blockSize)
cv_file.write("preFilterType",preFilterType)
cv_file.write("preFilterSize",preFilterSize)
cv_file.write("preFilterCap",preFilterCap)
cv_file.write("textureThreshold",textureThreshold)
cv_file.write("uniquenessRatio",uniquenessRatio)
cv_file.write("speckleRange",speckleRange)
cv_file.write("speckleWindowSize",speckleWindowSize)
cv_file.write("disp12MaxDiff",disp12MaxDiff)
cv_file.write("minDisparity",minDisparity)
cv_file.write("M",39.075)
cv_file.release()
    </code></pre>
    <br />
    <p>
      &emsp;Com o script adaptado, foram realizados diversos testes para ajustar os seguintes parâmetros:
    </p>
    <ul>
      <li><strong>numDisparities</strong>: número máximo de disparidades consideradas pelo algoritmo;</li>
      <li><strong>blockSize</strong>: tamanho da janela usada para comparar blocos entre as imagens;</li>
      <li><strong>preFilterCap</strong>: valor de normalização das imagens antes da correspondência;</li>
      <li><strong>uniquenessRatio</strong>: razão usada para garantir que a correspondência encontrada seja única;</li>
      <li><strong>textureThreshold</strong>: limiar para ignorar áreas com pouca textura;</li>
      <li><strong>speckleWindowSize</strong> e <strong>speckleRange</strong>: parâmetros para filtragem de ruído
        (“speckles”) no mapa gerado.</li>
    </ul>
    <br />
    <p>
      &emsp;Durante o processo de ajuste, observou-se que pequenas variações nesses parâmetros impactam
      significativamente a qualidade do mapa de disparidade. Parâmetros muito baixos produziam mapas com muito ruído e
      inconsistências, enquanto valores muito altos podiam suavizar excessivamente os detalhes, perdendo informação de
      profundidade. Portanto, o ajuste fino foi feito com base em observações visuais da cena e validação posterior nas
      medidas de profundidade.
    </p>
    <p>
      &emsp;Ao final da etapa, o mapa de disparidade foi gerado e foi salvo no arquivo
      <strong>depth_estimation_params_py.xml</strong>. Este arquivo armazena não apenas o mapa em si, mas também os
      parâmetros utilizados para gerá-lo, sendo essencial para as etapas seguintes de conversão em mapa de profundidade
      e para as medições de distância automatizadas.
    </p>
    <br />
    <h3>Conversão do Mapa de Disparidade em Mapa de Profundidade</h3>
    <br />
    <p>&emsp; Após a obtenção do mapa de disparidade com base nas imagens capturadas pela câmera estéreo e nos
      parâmetros calibrados, o próximo passo consistiu na conversão dessa informação em um mapa de profundidade. Essa
      etapa é fundamental para transformar as diferenças de posição (disparidades) detectadas entre os pares de imagens
      em valores métricos que representam a distância real dos objetos à câmera.</p>

    <p>&emsp; Para realizar a conversão de forma prática, utilizamos o script disparity2depth_calib.py, que foi
      previamente adaptado para realizar a leitura dos parâmetros de calibração armazenados no arquivo params_py.xml,
      assim como do mapa de disparidade salvo em depth_estimation_params_py.xml. Este script carrega o mapa de
      disparidade gerado, aplica a fórmula acima utilizando os parâmetros reais da câmera estéreo, e calcula a matriz de
      profundidade correspondente.</p>

      <pre><code class="language-python">
import numpy as np 
import cv2
import matplotlib
import matplotlib.pyplot as plt


# Check for left and right camera IDs
# These values can change depending on the system
CamL_id = 2 # Camera ID for left camera
CamR_id = 0 # Camera ID for right camera

CamL= cv2.VideoCapture(CamL_id)
CamR= cv2.VideoCapture(CamR_id)

# Reading the mapping values for stereo image rectification
cv_file = cv2.FileStorage("params_py.xml", cv2.FILE_STORAGE_READ)
Left_Stereo_Map_x = cv_file.getNode("Left_Stereo_Map_x").mat()
Left_Stereo_Map_y = cv_file.getNode("Left_Stereo_Map_y").mat()
Right_Stereo_Map_x = cv_file.getNode("Right_Stereo_Map_x").mat()
Right_Stereo_Map_y = cv_file.getNode("Right_Stereo_Map_y").mat()
cv_file.release()

# These parameters can vary according to the setup
# Keeping the target object at max_dist we store disparity values
# after every sample_delta distance.
max_dist = 30 # max distance to keep the target object (in cm)
min_dist = 10 # Minimum distance the stereo setup can measure (in cm)
sample_delta = 5 # Distance between two sampling points (in cm)

Z = max_dist 
Value_pairs = []

disp_map = np.zeros((600,600,3))


# Reading the stored the StereoBM parameters
cv_file = cv2.FileStorage("depth_estmation_params_py.xml", cv2.FILE_STORAGE_READ)
numDisparities = int(cv_file.getNode("numDisparities").real())
blockSize = int(cv_file.getNode("blockSize").real())
preFilterType = int(cv_file.getNode("preFilterType").real())
preFilterSize = int(cv_file.getNode("preFilterSize").real())
preFilterCap = int(cv_file.getNode("preFilterCap").real())
textureThreshold = int(cv_file.getNode("textureThreshold").real())
uniquenessRatio = int(cv_file.getNode("uniquenessRatio").real())
speckleRange = int(cv_file.getNode("speckleRange").real())
speckleWindowSize = int(cv_file.getNode("speckleWindowSize").real())
disp12MaxDiff = int(cv_file.getNode("disp12MaxDiff").real())
minDisparity = int(cv_file.getNode("minDisparity").real())
M = cv_file.getNode("M").real()
cv_file.release()

# Defining callback functions for mouse events
def mouse_click(event,x,y,flags,param):
	global Z
	if event == cv2.EVENT_LBUTTONDBLCLK:
		if disparity[y,x] > 0:
			Value_pairs.append([Z,disparity[y,x]])
			print("Distance: %r cm  | Disparity: %r"%(Z,disparity[y,x]))
			Z-=sample_delta
			


cv2.namedWindow('disp',cv2.WINDOW_NORMAL)
cv2.resizeWindow('disp',600,600)
cv2.namedWindow('left image',cv2.WINDOW_NORMAL)
cv2.resizeWindow('left image',600,600)
cv2.setMouseCallback('disp',mouse_click)

# Creating an object of StereoBM algorithm
stereo = cv2.StereoBM_create()

while True:

	# Capturing and storing left and right camera images
	retR, imgR= CamR.read()
	retL, imgL= CamL.read()
	
	# Proceed only if the frames have been captured
	if retL and retR:
		imgR_gray = cv2.cvtColor(imgR,cv2.COLOR_BGR2GRAY)
		imgL_gray = cv2.cvtColor(imgL,cv2.COLOR_BGR2GRAY)

		# Applying stereo image rectification on the left image
		Left_nice= cv2.remap(imgL_gray,
							Left_Stereo_Map_x,
							Left_Stereo_Map_y,
							cv2.INTER_LANCZOS4,
							cv2.BORDER_CONSTANT,
							0)
		
		# Applying stereo image rectification on the right image
		Right_nice= cv2.remap(imgR_gray,
							Right_Stereo_Map_x,
							Right_Stereo_Map_y,
							cv2.INTER_LANCZOS4,
							cv2.BORDER_CONSTANT,
							0)

		# Setting the updated parameters before computing disparity map
		stereo.setNumDisparities(numDisparities)
		stereo.setBlockSize(blockSize)
		stereo.setPreFilterType(preFilterType)
		stereo.setPreFilterSize(preFilterSize)
		stereo.setPreFilterCap(preFilterCap)
		stereo.setTextureThreshold(textureThreshold)
		stereo.setUniquenessRatio(uniquenessRatio)
		stereo.setSpeckleRange(speckleRange)
		stereo.setSpeckleWindowSize(speckleWindowSize)
		stereo.setDisp12MaxDiff(disp12MaxDiff)
		stereo.setMinDisparity(minDisparity)

		# Calculating disparity using the StereoBM algorithm
		disparity = stereo.compute(Left_nice,Right_nice)
		# NOTE: compute returns a 16bit signed single channel image,
		# CV_16S containing a disparity map scaled by 16. Hence it 
		# is essential to convert it to CV_16S and scale it down 16 times.

		# Converting to float32 
		disparity = disparity.astype(np.float32)

		# Scaling down the disparity values and normalizing them 
		disparity = (disparity/16.0 - minDisparity)/numDisparities

		# Displaying the disparity map
		cv2.imshow("disp",disparity)
		cv2.imshow("left image",imgL)

		if cv2.waitKey(1) == 27:
			break
		
		if Z < min_dist:
			break
	
	else:
		CamL= cv2.VideoCapture(CamL_id)
		CamR= cv2.VideoCapture(CamR_id)

# solving for M in the following equation
# ||    depth = M * (1/disparity)   ||
# for N data points coeff is Nx2 matrix with values 
# 1/disparity, 1
# and depth is Nx1 matrix with depth values

value_pairs = np.array(Value_pairs)
z = value_pairs[:,0]
disp = value_pairs[:,1]
disp_inv = 1/disp

# Plotting the relation depth and corresponding disparity
fig, (ax1,ax2) = plt.subplots(1,2,figsize=(12,6))
ax1.plot(disp, z, 'o-')
ax1.set(xlabel='Normalized disparity value', ylabel='Depth from camera (cm)',
       title='Relation between depth \n and corresponding disparity')
ax1.grid()
ax2.plot(disp_inv, z, 'o-')
ax2.set(xlabel='Inverse disparity value (1/disp) ', ylabel='Depth from camera (cm)',
       title='Relation between depth \n and corresponding inverse disparity')
ax2.grid()
plt.show()


# Solving for M using least square fitting with QR decomposition method
coeff = np.vstack([disp_inv, np.ones(len(disp_inv))]).T
ret, sol = cv2.solve(coeff,z,flags=cv2.DECOMP_QR)
M = sol[0,0]
C = sol[1,0]
print("Value of M = ",M)


# Storing the updated value of M along with the stereo parameters
cv_file = cv2.FileStorage("depth_estmation_params_py.xml", cv2.FILE_STORAGE_WRITE)
cv_file.write("numDisparities",numDisparities)
cv_file.write("blockSize",blockSize)
cv_file.write("preFilterType",preFilterType)
cv_file.write("preFilterSize",preFilterSize)
cv_file.write("preFilterCap",preFilterCap)
cv_file.write("textureThreshold",textureThreshold)
cv_file.write("uniquenessRatio",uniquenessRatio)
cv_file.write("speckleRange",speckleRange)
cv_file.write("speckleWindowSize",speckleWindowSize)
cv_file.write("disp12MaxDiff",disp12MaxDiff)
cv_file.write("minDisparity",minDisparity)
cv_file.write("M",M)
cv_file.release()
      </code></pre>

    <p>&emsp; Durante a execução, o script atualiza o próprio arquivo depth_estimation_params_py.xml, acrescentando a
      matriz de profundidade para posterior uso em outras aplicações, como estimativa de distâncias e navegação por
      obstáculos. O uso de arquivos XML para persistência dos parâmetros e dados intermediários permitiu uma integração
      simples e consistente entre as diferentes etapas do processo.</p>

    <br />

    <h3>Calibração Estéreo</h3>
    <br />
    <p>&emsp; O processo iniciou com a calibração estéreo da câmera, utilizando o padrão de tabuleiro de xadrez para
      estimar os parâmetros intrínsecos e extrínsecos. As imagens foram capturadas com o script capture_images.py e
      processadas pelo calibrate_you.py, gerando o arquivo params_py.xml, que armazena as matrizes de
      calibração e distorção. Esses códigos podem ser consultados na página do <a href="../lab03/lab03.html"
        target="_blank">Laboratório 3</a>.</p>

    <br />

    <br />
    <h2>Análise e discussão dos estudos realizados</h2>
    <br />
    <p>&emsp;</p>

    <br />
    <h2>Conclusões</h2>
    <br />
    <p>&emsp;</p>

    <br />
    <h2>Referências</h2>
    <br />

    <ul>
      <li>
        <p>[1] Making A Low-Cost Stereo Camera Using OpenCV:</p>
        <p>
          <a href="https://learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/" target="_blank">
            https://learnopencv.com/making-a-low-cost-stereo-camera-using-opencv/
          </a>
        </p>
        <p>
          Código:
          <a href="https://github.com/spmallick/learnopencv/tree/master/stereo-camera" target="_blank">
            https://github.com/spmallick/learnopencv/tree/master/stereo-camera
          </a>
        </p>
      </li>

      <li>
        <p>[2] Introduction to Epipolar Geometry and Stereo Vision:</p>
        <p>
          <a href="https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/" target="_blank">
            https://learnopencv.com/introduction-to-epipolar-geometry-and-stereo-vision/
          </a>
        </p>
        <p>
          Código:
          <a href="https://github.com/spmallick/learnopencv/tree/master/EpipolarGeometryAndStereoVision"
            target="_blank">
            https://github.com/spmallick/learnopencv/tree/master/EpipolarGeometryAndStereoVision
          </a>
        </p>
      </li>

      <li>
        <p>[3] Stereo Camera Depth Estimation With OpenCV (Python/C++):</p>
        <p>
          <a href="https://learnopencv.com/depth-perception-using-stereo-camera-python-c/" target="_blank">
            https://learnopencv.com/depth-perception-using-stereo-camera-python-c/
          </a>
        </p>
        <p>
          Código:
          <a href="https://github.com/spmallick/learnopencv/tree/master/Depth-Perception-Using-Stereo-Camera"
            target="_blank">
            https://github.com/spmallick/learnopencv/tree/master/Depth-Perception-Using-Stereo-Camera
          </a>
        </p>
      </li>

      <li>
        <p>[4] Depth Map from Stereo Images:</p>
        <p>
          <a href="https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html" target="_blank">
            https://docs.opencv.org/4.x/dd/d53/tutorial_py_depthmap.html
          </a>
        </p>
      </li>

      <li>
        <p>[5] Geometry of Image Formation:</p>
        <p>
          <a href="https://learnopencv.com/geometry-of-image-formation/" target="_blank">
            https://learnopencv.com/geometry-of-image-formation/
          </a>
        </p>
      </li>
    </ul>
  </div>
</body>

</html>